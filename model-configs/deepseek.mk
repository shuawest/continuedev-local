MODEL_REPO=TheBloke/Deepseek-Coder-6.7B-Instruct-GGUF
MODEL_FILE=deepseek-coder-6.7b-instruct.Q4_K_M.gguf
MODEL_DISPLAY=DeepSeek
MODEL_PROVIDER=openai
MODEL_NAME=deepseek-chat
MODEL_API_BASE=http://localhost:8000/v1
CHAT_TEMPERATURE=0.7
CHAT_MAX_TOKENS=2048
CODE_TEMPERATURE=0.2
CODE_MAX_TOKENS=512
CONFIG_TEMPLATE=config-templates/deepseek.tmpl
