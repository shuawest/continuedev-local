MODEL_REPO=TheBloke/CodeLlama-7B-Instruct-GGUF
MODEL_FILE=codellama-7b-instruct.Q4_K_M.gguf
MODEL_DISPLAY=CodeLlamaInstruct
MODEL_PROVIDER=openai
MODEL_NAME=codellama-chat
MODEL_API_BASE=http://localhost:8000/v1
CHAT_TEMPERATURE=0.6
CHAT_MAX_TOKENS=2048
CODE_TEMPERATURE=0.15
CODE_MAX_TOKENS=512
CONFIG_TEMPLATE=config-templates/codellama.tmpl
